{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "97024cf4-c930-4aa1-a13f-ecdcc2462afe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datasets import load_dataset\n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5404d6b6-6ce1-48df-8999-7da3fb082662",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This needs to be defined by the drop down in the UI\n",
    "subgroup1 = \"woman\"\n",
    "subgroup2 = \"man\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "18bf08cc-e18f-49fc-bae7-f03a9a492baa",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = load_dataset(\"c4\", \"en\", split= \"train\", streaming = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8ca6ee78-6f96-45e2-8dad-ec745c953d10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: Just taking the first 10000 instances.\n"
     ]
    }
   ],
   "source": [
    "grab_n = 10000\n",
    "# For streaming data\n",
    "print('Note: Just taking the first %s instances.' % grab_n)\n",
    "data_head = data.take(grab_n)\n",
    "#data_head = [[\"there is a woman with a hairbrush\"],[\"there is a woman with a hairbrush\"],[\"there is a woman with a hairbrush\"],[\"there is a man with a dog\"],[\"there is a man with a dog\"]]\n",
    "df = pd.DataFrame(data_head, columns=[\"text\"])\n",
    "# If not streaming, use:\n",
    "#df = pd.json_normalize(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "46d4d0c8-fc7c-4e99-8207-2e93d1c9b732",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_vocab_frequencies(df):\n",
    "    \"\"\"\n",
    "    Based on an input pandas DataFrame with a 'text' column, \n",
    "    this function will count the occurrences of all words\n",
    "    with a frequency higher than 'cutoff' and will return another DataFrame\n",
    "    with the rows corresponding to the different vocabulary words\n",
    "    and the column to the count count of that word.\n",
    "    \"\"\"\n",
    "    # Move this up as a constant in larger code.\n",
    "    batch_size = 10\n",
    "    \n",
    "    # We do this to calculate per-word statistics\n",
    "    df['text'] = df['text'].str.lower()\n",
    "    # Regex for pulling out single words\n",
    "    cvec = CountVectorizer(token_pattern=u\"(?u)\\\\b\\\\w+\\\\b\", lowercase=True)\n",
    "    \n",
    "    # We also do this because we need to have the tokenization per sentence \n",
    "    # so that we can look at co-occurrences of words across sentences for nPMI calculation\n",
    "    sent_tokenizer = cvec.build_tokenizer()\n",
    "    df['tokenized'] = df.text.apply(sent_tokenizer)\n",
    "    \n",
    "    # Fast calculation of single word counts\n",
    "    cvec.fit(df.text)\n",
    "    document_matrix = cvec.transform(df.text)\n",
    "    batches = np.linspace(0, df.shape[0], batch_size).astype(int)\n",
    "    i = 0\n",
    "    tf = []\n",
    "    while i < len(batches) - 1:\n",
    "        batch_result = np.sum(document_matrix[batches[i]:batches[i+1]].toarray(), axis=0)\n",
    "        tf.append(batch_result)\n",
    "        i += 1\n",
    "    term_freq_df = pd.DataFrame([np.sum(tf, axis=0)], columns=cvec.get_feature_names()).transpose()\n",
    "    \n",
    "    # Now organize everything into the dataframes\n",
    "    term_freq_df.columns = ['count']\n",
    "    term_freq_df.index.name = 'word'\n",
    "    sorted_term_freq_df = pd.DataFrame(term_freq_df.sort_values(by='count', ascending=False)['count'])\n",
    "    return sorted_term_freq_df, df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c5b291a4-088e-463e-8a5e-326bcb0d9dd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       count  proportion\n",
      "word                    \n",
      "the   186019    0.050628\n",
      "and   107893    0.029365\n",
      "to    103090    0.028058\n",
      "of     89417    0.024336\n",
      "a      81307    0.022129\n",
      "             count    proportion\n",
      "word                            \n",
      "interestel       1  2.721674e-07\n",
      "interethnic      1  2.721674e-07\n",
      "interfaced       1  2.721674e-07\n",
      "interfacing      1  2.721674e-07\n",
      "ðŒ¼ðŒ¿ðŒ½ðŒ³ðƒ            1  2.721674e-07\n"
     ]
    }
   ],
   "source": [
    "term_df, df = count_vocab_frequencies(df)\n",
    "# p(word).  Note that multiple occurrences of a word in a sentence increases its probability.\n",
    "# We may want to do something about that.\n",
    "term_df['proportion'] = term_df['count']/float(sum(term_df['count']))\n",
    "# Sanity check\n",
    "print(term_df.head())\n",
    "print(term_df.tail())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8202c12e-6d02-4dbc-a896-c1ce1d3b34e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_PMI(df_coo, subgroup):\n",
    "    # PMI(x;y) = h(y) - h(y|x)\n",
    "    #          = h(subgroup) - h(subgroup|word)\n",
    "    #          = log (p(subgroup|word) / p(subgroup))\n",
    "\n",
    "    # p(subgroup)\n",
    "    subgroup_prob = term_df.loc[subgroup]['proportion']\n",
    "    # Apply a function to all words to calculate log p(subgroup|word)\n",
    "    # The word is indexed by mlb.classes_ ; \n",
    "    # we pull out the word using the mlb.classes_ index and then get its count using our main term_df\n",
    "    pmi_df = pd.DataFrame(df_coo.apply(lambda x: np.log(x.values/term_df.loc[mlb.classes_[x.index]]['count']/subgroup_prob)))\n",
    "    # If all went well, this will be correlated with high frequency words\n",
    "    # Until normalizing\n",
    "    return pmi_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c7207c16-7f2c-470a-b9d7-6a52e03b6a5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/margaretmitchell/opt/anaconda3/lib/python3.8/site-packages/pandas/core/arraylike.py:364: RuntimeWarning: divide by zero encountered in log\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "\n",
    "# Makes a sparse vector (shape: # sentences x # words),\n",
    "# with the count of each word per sentence.\n",
    "mlb = MultiLabelBinarizer()\n",
    "df_mlb = pd.DataFrame(mlb.fit_transform(df['tokenized']))\n",
    "df_pair = pd.DataFrame(columns=[subgroup1, subgroup2])\n",
    "for subgroup in (subgroup1, subgroup2):\n",
    "    # Index of the subgroup word in the sparse vector\n",
    "    subgroup_idx = np.where(mlb.classes_ == subgroup)[0][0]\n",
    "    # Dataframe for the subgroup (with counts)\n",
    "    df_subgroup = df_mlb.iloc[:, subgroup_idx]\n",
    "    # Create cooccurence matrix for the given subgroup and all other words.\n",
    "    # Note it also includes the word itself, so that count should be subtracted \n",
    "    # (the word will always co-occur with itself)\n",
    "    df_coo = pd.DataFrame(df_mlb.T.dot(df_subgroup))#.drop(index=subgroup_idx, axis=1)\n",
    "    pmi_df = get_PMI(df_coo, subgroup)\n",
    "    df_pair[subgroup] = pmi_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d670174e-61b4-4af8-9203-540ec928dcec",
   "metadata": {},
   "outputs": [],
   "source": [
    "pmi_bias = pd.DataFrame(df_pair[subgroup1] - df_pair[subgroup2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "986c4cb3-ba23-4bcd-8f08-1d17c01a7f0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Words that only occur with one or the other\n",
    "s1_only_words = pmi_bias[pmi_bias[0].values==np.inf]\n",
    "s2_only_words = pmi_bias[pmi_bias[0].values==-np.inf]\n",
    "\n",
    "# Filter\n",
    "pmi_bias_filtered = pmi_bias[(np.inf > pmi_bias[0]) & (pmi_bias[0] > -np.inf)].sort_values(by=[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "60ec116a-29d5-4b88-8aac-cd3ced1aa8e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 50 most man-biased words\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>word</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>pure</th>\n",
       "      <td>-2.055189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>foot</th>\n",
       "      <td>-2.055189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>failed</th>\n",
       "      <td>-1.864134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>decade</th>\n",
       "      <td>-1.692284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>route</th>\n",
       "      <td>-1.692284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>leg</th>\n",
       "      <td>-1.627745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>minds</th>\n",
       "      <td>-1.627745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>squad</th>\n",
       "      <td>-1.627745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>league</th>\n",
       "      <td>-1.627745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gained</th>\n",
       "      <td>-1.558752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>software</th>\n",
       "      <td>-1.558752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>versions</th>\n",
       "      <td>-1.484644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>premier</th>\n",
       "      <td>-1.484644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>origin</th>\n",
       "      <td>-1.484644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wave</th>\n",
       "      <td>-1.484644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>returns</th>\n",
       "      <td>-1.484644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>precisely</th>\n",
       "      <td>-1.484644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>instantly</th>\n",
       "      <td>-1.404602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>milk</th>\n",
       "      <td>-1.404602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>duties</th>\n",
       "      <td>-1.404602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>steady</th>\n",
       "      <td>-1.404602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>drinks</th>\n",
       "      <td>-1.404602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>thinks</th>\n",
       "      <td>-1.404602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>blocked</th>\n",
       "      <td>-1.404602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fish</th>\n",
       "      <td>-1.404602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>desires</th>\n",
       "      <td>-1.404602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>additionally</th>\n",
       "      <td>-1.404602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>actor</th>\n",
       "      <td>-1.404602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>compare</th>\n",
       "      <td>-1.404602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>contract</th>\n",
       "      <td>-1.317590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ireland</th>\n",
       "      <td>-1.317590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>encounter</th>\n",
       "      <td>-1.317590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>-1.317590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>delay</th>\n",
       "      <td>-1.317590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cooking</th>\n",
       "      <td>-1.317590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1997</th>\n",
       "      <td>-1.317590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ban</th>\n",
       "      <td>-1.317590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>engine</th>\n",
       "      <td>-1.317590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>captured</th>\n",
       "      <td>-1.317590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cap</th>\n",
       "      <td>-1.317590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gotta</th>\n",
       "      <td>-1.222280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fees</th>\n",
       "      <td>-1.222280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>processing</th>\n",
       "      <td>-1.222280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>length</th>\n",
       "      <td>-1.222280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>composed</th>\n",
       "      <td>-1.222280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>indicate</th>\n",
       "      <td>-1.222280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>comic</th>\n",
       "      <td>-1.222280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>supposedly</th>\n",
       "      <td>-1.222280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>guarantee</th>\n",
       "      <td>-1.222280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>garage</th>\n",
       "      <td>-1.222280</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     0\n",
       "word                  \n",
       "pure         -2.055189\n",
       "foot         -2.055189\n",
       "failed       -1.864134\n",
       "decade       -1.692284\n",
       "route        -1.692284\n",
       "leg          -1.627745\n",
       "minds        -1.627745\n",
       "squad        -1.627745\n",
       "league       -1.627745\n",
       "gained       -1.558752\n",
       "software     -1.558752\n",
       "versions     -1.484644\n",
       "premier      -1.484644\n",
       "origin       -1.484644\n",
       "wave         -1.484644\n",
       "returns      -1.484644\n",
       "precisely    -1.484644\n",
       "instantly    -1.404602\n",
       "milk         -1.404602\n",
       "duties       -1.404602\n",
       "steady       -1.404602\n",
       "drinks       -1.404602\n",
       "thinks       -1.404602\n",
       "blocked      -1.404602\n",
       "fish         -1.404602\n",
       "desires      -1.404602\n",
       "additionally -1.404602\n",
       "actor        -1.404602\n",
       "compare      -1.404602\n",
       "contract     -1.317590\n",
       "ireland      -1.317590\n",
       "encounter    -1.317590\n",
       "38           -1.317590\n",
       "delay        -1.317590\n",
       "cooking      -1.317590\n",
       "1997         -1.317590\n",
       "ban          -1.317590\n",
       "engine       -1.317590\n",
       "captured     -1.317590\n",
       "cap          -1.317590\n",
       "gotta        -1.222280\n",
       "fees         -1.222280\n",
       "processing   -1.222280\n",
       "length       -1.222280\n",
       "composed     -1.222280\n",
       "indicate     -1.222280\n",
       "comic        -1.222280\n",
       "supposedly   -1.222280\n",
       "guarantee    -1.222280\n",
       "garage       -1.222280"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n = 50\n",
    "print(\"Top %s most %s-biased words\" % (n,subgroup2))\n",
    "pmi_bias_filtered[:n]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8bcb965a-4709-4d03-b682-bc8c1af41175",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 50 most woman-biased words\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>word</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>quit</th>\n",
       "      <td>2.872065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>representation</th>\n",
       "      <td>2.689743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>vitamins</th>\n",
       "      <td>2.689743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>swedish</th>\n",
       "      <td>2.689743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>complement</th>\n",
       "      <td>2.689743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>flights</th>\n",
       "      <td>2.466600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mai</th>\n",
       "      <td>2.466600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>childbirth</th>\n",
       "      <td>2.466600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>miraculously</th>\n",
       "      <td>2.466600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alice</th>\n",
       "      <td>2.466600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>murray</th>\n",
       "      <td>2.466600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>grooming</th>\n",
       "      <td>2.466600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>strengthening</th>\n",
       "      <td>2.466600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>workplace</th>\n",
       "      <td>2.466600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>coaster</th>\n",
       "      <td>2.466600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>shoots</th>\n",
       "      <td>2.466600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>activism</th>\n",
       "      <td>2.466600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>malaysia</th>\n",
       "      <td>2.466600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>woman</th>\n",
       "      <td>2.221705</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>honorary</th>\n",
       "      <td>2.178917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>immensely</th>\n",
       "      <td>2.178917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>surveys</th>\n",
       "      <td>2.178917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>satellite</th>\n",
       "      <td>2.178917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>testified</th>\n",
       "      <td>2.178917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>booster</th>\n",
       "      <td>2.178917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dumb</th>\n",
       "      <td>2.178917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>investigator</th>\n",
       "      <td>2.178917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>brighten</th>\n",
       "      <td>2.178917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>overlap</th>\n",
       "      <td>2.178917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>frustrated</th>\n",
       "      <td>2.178917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>corps</th>\n",
       "      <td>2.178917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>negotiation</th>\n",
       "      <td>2.178917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>flooded</th>\n",
       "      <td>2.178917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>attire</th>\n",
       "      <td>2.178917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>forthcoming</th>\n",
       "      <td>2.178917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cocktail</th>\n",
       "      <td>2.178917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>beth</th>\n",
       "      <td>2.178917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>epidemic</th>\n",
       "      <td>2.178917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>compound</th>\n",
       "      <td>2.178917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>220</th>\n",
       "      <td>2.178917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pregnancies</th>\n",
       "      <td>2.178917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ramp</th>\n",
       "      <td>2.178917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>translate</th>\n",
       "      <td>2.178917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>chatter</th>\n",
       "      <td>2.178917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>doll</th>\n",
       "      <td>2.178917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>chambers</th>\n",
       "      <td>2.178917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>clad</th>\n",
       "      <td>2.178917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>julia</th>\n",
       "      <td>2.178917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>interact</th>\n",
       "      <td>2.178917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rituals</th>\n",
       "      <td>2.178917</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       0\n",
       "word                    \n",
       "quit            2.872065\n",
       "representation  2.689743\n",
       "vitamins        2.689743\n",
       "swedish         2.689743\n",
       "complement      2.689743\n",
       "flights         2.466600\n",
       "mai             2.466600\n",
       "childbirth      2.466600\n",
       "miraculously    2.466600\n",
       "alice           2.466600\n",
       "murray          2.466600\n",
       "grooming        2.466600\n",
       "strengthening   2.466600\n",
       "workplace       2.466600\n",
       "coaster         2.466600\n",
       "shoots          2.466600\n",
       "activism        2.466600\n",
       "malaysia        2.466600\n",
       "woman           2.221705\n",
       "honorary        2.178917\n",
       "immensely       2.178917\n",
       "surveys         2.178917\n",
       "satellite       2.178917\n",
       "testified       2.178917\n",
       "booster         2.178917\n",
       "dumb            2.178917\n",
       "investigator    2.178917\n",
       "brighten        2.178917\n",
       "overlap         2.178917\n",
       "frustrated      2.178917\n",
       "corps           2.178917\n",
       "negotiation     2.178917\n",
       "flooded         2.178917\n",
       "attire          2.178917\n",
       "forthcoming     2.178917\n",
       "cocktail        2.178917\n",
       "beth            2.178917\n",
       "epidemic        2.178917\n",
       "compound        2.178917\n",
       "220             2.178917\n",
       "pregnancies     2.178917\n",
       "ramp            2.178917\n",
       "translate       2.178917\n",
       "chatter         2.178917\n",
       "doll            2.178917\n",
       "chambers        2.178917\n",
       "clad            2.178917\n",
       "julia           2.178917\n",
       "interact        2.178917\n",
       "rituals         2.178917"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Top %s most %s-biased words\" % (n,subgroup1))\n",
    "pmi_bias_filtered[-n:].sort_values(by=[0], ascending=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
